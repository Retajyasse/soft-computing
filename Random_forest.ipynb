{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrPDMF4keh06fzzb5Vnhek",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Retajyasse/soft-computing/blob/main/Random_forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auzM65ovVU9-",
        "outputId": "45f0efa3-7711-4a46-8398-fc89e20c389a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyswarms\n",
            "  Downloading pyswarms-1.3.0-py2.py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyswarms) (1.15.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pyswarms) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from pyswarms) (3.10.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from pyswarms) (25.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pyswarms) (4.67.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from pyswarms) (1.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from pyswarms) (6.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=1.3.1->pyswarms) (1.17.0)\n",
            "Downloading pyswarms-1.3.0-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/104.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyswarms\n",
            "Successfully installed pyswarms-1.3.0\n",
            "Dropped features: [' ROA(A) before interest and % after tax', ' ROA(B) before interest and depreciation after tax', ' Realized Sales Gross Margin', ' Pre-tax net Interest Rate', ' After-tax net Interest Rate', ' Continuous interest rate (after tax)', ' Net Value Per Share (A)', ' Net Value Per Share (C)', ' Per Share Net profit before tax (Yuan ¥)', ' Regular Net Profit Growth Rate', ' Net worth/Assets', ' Operating profit/Paid-in capital', ' Net profit before tax/Paid-in capital', ' Cash Flow to Sales', ' Current Liability to Liability', ' Current Liability to Equity', ' Net Income to Total Assets', ' Gross Profit to Sales', ' Liability to Equity']\n",
            "\n",
            "--- Random Forest (All features) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99      1320\n",
            "           1       0.64      0.20      0.31        44\n",
            "\n",
            "    accuracy                           0.97      1364\n",
            "   macro avg       0.81      0.60      0.65      1364\n",
            "weighted avg       0.96      0.97      0.96      1364\n",
            "\n",
            "Accuracy: 0.9707\n",
            "Precision: 0.6429\n",
            "Recall: 0.2045\n",
            "F1 Score: 0.3103\n"
          ]
        }
      ],
      "source": [
        "!pip install pyswarms  # uncomment if pyswarms not installed\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import pyswarms as ps  # for PSO\n",
        "\n",
        "# --- Load and preprocess dataset ---\n",
        "df = pd.read_csv('/content/sample_data/data.csv')  # change path if needed\n",
        "\n",
        "# Drop highly correlated features (threshold 0.9)\n",
        "corr_matrix = df.drop('Bankrupt?', axis=1).corr().abs()\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "to_drop = [col for col in upper.columns if any(upper[col] > 0.9)]\n",
        "df.drop(columns=to_drop, inplace=True)\n",
        "\n",
        "print(f\"Dropped features: {to_drop}\")\n",
        "\n",
        "X = df.drop('Bankrupt?', axis=1).values\n",
        "y = df['Bankrupt?'].values\n",
        "\n",
        "# Handle missing values\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X = imputer.fit_transform(X)  # Now X is a NumPy array with no NaNs\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# -------------------------\n",
        "# 1) ML baseline: Random Forest with all features\n",
        "# -------------------------\n",
        "model_ml = RandomForestClassifier(random_state=42)\n",
        "model_ml.fit(X_train, y_train)\n",
        "y_pred_ml = model_ml.predict(X_test)\n",
        "\n",
        "# Metrics function\n",
        "def print_metrics(y_true, y_pred, title=\"\"):\n",
        "    print(f\"\\n--- {title} ---\")\n",
        "    print(classification_report(y_true, y_pred, zero_division=0))\n",
        "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_true, y_pred, zero_division=0):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, zero_division=0):.4f}\")\n",
        "    print(f\"F1 Score: {f1_score(y_true, y_pred, zero_division=0):.4f}\")\n",
        "\n",
        "print_metrics(y_test, y_pred_ml, \"Random Forest (All features)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def fitness_function(chromosome, X_train, y_train):\n",
        "    if sum(chromosome) == 0:\n",
        "        return 0\n",
        "    X_subset = X_train[:, chromosome==1]\n",
        "    model = RandomForestClassifier(random_state=42)\n",
        "    scores = cross_val_score(model, X_subset, y_train, cv=3, scoring='accuracy')\n",
        "    return scores.mean()\n",
        "\n",
        "def run_ga_feature_selection(X_train, y_train, n_pop=20, n_gen=10, mutation_rate=0.1):\n",
        "    n_features = X_train.shape[1]\n",
        "    population = [np.random.randint(0, 2, n_features) for _ in range(n_pop)]\n",
        "\n",
        "    best_chromosome = None\n",
        "    best_fitness = 0\n",
        "\n",
        "    for gen in range(n_gen):\n",
        "        fitness_scores = np.array([fitness_function(ind, X_train, y_train) for ind in population])\n",
        "\n",
        "        # Select best\n",
        "        best_idx = np.argmax(fitness_scores)\n",
        "        if fitness_scores[best_idx] > best_fitness:\n",
        "            best_fitness = fitness_scores[best_idx]\n",
        "            best_chromosome = population[best_idx].copy()\n",
        "\n",
        "        # Selection (tournament)\n",
        "        selected = []\n",
        "        for _ in range(n_pop // 2):\n",
        "            i1, i2 = random.sample(range(n_pop), 2)\n",
        "            winner = population[i1] if fitness_scores[i1] > fitness_scores[i2] else population[i2]\n",
        "            selected.append(winner)\n",
        "\n",
        "        # Crossover + Mutation\n",
        "        children = []\n",
        "        while len(children) < n_pop:\n",
        "            p1, p2 = random.sample(selected, 2)\n",
        "            point = random.randint(1, n_features - 1)\n",
        "            child = np.concatenate([p1[:point], p2[point:]])\n",
        "            # mutation\n",
        "            for i in range(n_features):\n",
        "                if random.random() < mutation_rate:\n",
        "                    child[i] = 1 - child[i]\n",
        "            children.append(child)\n",
        "        population = children\n",
        "        print(f\"GA Generation {gen+1}: Best fitness = {best_fitness:.4f}\")\n",
        "\n",
        "    return best_chromosome.astype(bool)\n",
        "\n",
        "# Run GA\n",
        "best_chromosome = run_ga_feature_selection(X_train, y_train)\n",
        "\n",
        "# Train Random Forest on GA selected features\n",
        "X_train_ga = X_train[:, best_chromosome]\n",
        "X_test_ga = X_test[:, best_chromosome]\n",
        "model_ga = RandomForestClassifier(random_state=42)\n",
        "model_ga.fit(X_train_ga, y_train)\n",
        "y_pred_ga = model_ga.predict(X_test_ga)\n",
        "\n",
        "print_metrics(y_test, y_pred_ga, \"Random Forest + GA Feature Selection\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bstcYQyu7RyB",
        "outputId": "cdfb452b-dea4-4da5-c39f-1cd241d68d06"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GA Generation 1: Best fitness = 0.9701\n",
            "GA Generation 2: Best fitness = 0.9707\n",
            "GA Generation 3: Best fitness = 0.9707\n",
            "GA Generation 4: Best fitness = 0.9707\n",
            "GA Generation 5: Best fitness = 0.9707\n",
            "GA Generation 6: Best fitness = 0.9707\n",
            "GA Generation 7: Best fitness = 0.9709\n",
            "GA Generation 8: Best fitness = 0.9709\n",
            "GA Generation 9: Best fitness = 0.9709\n",
            "GA Generation 10: Best fitness = 0.9709\n",
            "\n",
            "--- Random Forest + GA Feature Selection ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98      1320\n",
            "           1       0.67      0.14      0.23        44\n",
            "\n",
            "    accuracy                           0.97      1364\n",
            "   macro avg       0.82      0.57      0.61      1364\n",
            "weighted avg       0.96      0.97      0.96      1364\n",
            "\n",
            "Accuracy: 0.9699\n",
            "Precision: 0.6667\n",
            "Recall: 0.1364\n",
            "F1 Score: 0.2264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pyswarms as ps\n",
        "\n",
        "# Assume X, y are your dataset features and labels\n",
        "# X, y = ...\n",
        "\n",
        "# 1. Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# 2. Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 3. Define PSO fitness function with 3-fold CV and Random Forest model\n",
        "def pso_fitness(x):\n",
        "    scores = []\n",
        "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    for particle in x:\n",
        "        mask = particle > 0.5\n",
        "        if np.sum(mask) == 0:\n",
        "            scores.append(0.0)\n",
        "            continue\n",
        "        cols = np.where(mask)[0]\n",
        "        fold_acc = []\n",
        "        for train_idx, val_idx in skf.split(X_train, y_train):\n",
        "            X_tr, X_val = X_train[train_idx][:, cols], X_train[val_idx][:, cols]\n",
        "            y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "            model = RandomForestClassifier(\n",
        "                n_estimators=100,\n",
        "                max_depth=None,\n",
        "                random_state=42,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "            model.fit(X_tr, y_tr)\n",
        "            y_pred = model.predict(X_val)\n",
        "            fold_acc.append(accuracy_score(y_val, y_pred))\n",
        "        scores.append(np.mean(fold_acc))\n",
        "    return -np.array(scores)  # PSO minimizes cost\n",
        "\n",
        "# 4. Set PSO parameters — fewer particles and iterations for speed\n",
        "options = {'c1': 2.0, 'c2': 2.0, 'w': 0.7}\n",
        "optimizer = ps.single.GlobalBestPSO(\n",
        "    n_particles=10,              # fewer particles = faster but less exploration\n",
        "    dimensions=X_train.shape[1],\n",
        "    options=options\n",
        ")\n",
        "\n",
        "# 5. Run the optimization\n",
        "cost, pos = optimizer.optimize(pso_fitness, iters=50)\n",
        "\n",
        "# 6. Selected features mask from PSO position\n",
        "selected_features_pso = pos > 0.5\n",
        "print(f\"PSO selected {np.sum(selected_features_pso)} features.\")\n",
        "\n",
        "# 7. Train final Random Forest model on selected features with original data split\n",
        "final_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=None,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "final_model.fit(X_train[:, selected_features_pso], y_train)\n",
        "y_pred = final_model.predict(X_test[:, selected_features_pso])\n",
        "\n",
        "# 8. Print evaluation metrics\n",
        "print(\"PSO + Random Forest Results:\")\n",
        "print(f\"Accuracy:  {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall:    {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1 Score:  {f1_score(y_test, y_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JDvW4lR_qnu",
        "outputId": "664a7058-b691-4d4e-c102-5c8399e8683e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-18 01:25:13,464 - pyswarms.single.global_best - INFO - Optimize for 50 iters with {'c1': 2.0, 'c2': 2.0, 'w': 0.7}\n",
            "pyswarms.single.global_best: 100%|██████████|50/50, best_cost=-0.971\n",
            "2025-05-18 01:55:23,729 - pyswarms.single.global_best - INFO - Optimization finished | best cost: -0.9712192311406328, best pos: [-0.78319149  1.42389677  1.37276331  0.92650772 -1.8412715   1.16382764\n",
            "  0.02008362  0.53584219 -2.57914117  0.53956785  2.11003775  1.39621795\n",
            "  0.71048249 -0.44174793  0.15290495  6.15779046 -1.18518715  0.19788569\n",
            "  0.81931796 -1.11947382  1.08262495 -0.91098825  0.36142333  0.79744925\n",
            " -0.98459609 -0.28643871  0.15706491  1.03051864  1.09091992  1.432861\n",
            "  0.36513383  0.54465925  1.71054237  0.85392242  0.61816198 -2.60281244\n",
            "  0.31194731  1.28147128 -2.20520559  1.47106539 -0.38102411 -0.7576481\n",
            "  2.80696023  1.95336973  1.1103075   0.55291102  0.42051521  0.2465684\n",
            "  0.95593634  0.69213764 -1.10884781 -0.0117967   1.8977082   0.65629886\n",
            "  5.8634242  -0.72858395  0.9027324   1.00066344  0.98683304  2.00527705\n",
            "  1.55289773  1.93133229  0.10343725  0.14660699  0.21722228  0.51120151\n",
            "  0.52805698  1.02628924  0.63977719 -0.3041358   0.08032644 -0.14202898\n",
            "  0.53969988  0.69244552  0.7862639   0.68262203]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSO selected 45 features.\n",
            "PSO + Random Forest Results:\n",
            "Accuracy:  0.9721\n",
            "Precision: 0.8000\n",
            "Recall:    0.1818\n",
            "F1 Score:  0.2963\n"
          ]
        }
      ]
    }
  ]
}